{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a91e501",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be5875de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,Flatten,Conv2D,MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.initializers import GlorotUniform, RandomUniform\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36d4f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_images():\n",
    "\n",
    "    folder='D:\\dersler\\cng483\\Proje3\\CNG483Project 3\\Database'\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img=np.array(img)\n",
    "            img=img.astype('float32')\n",
    "            images.append(img)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f405f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_crop():\n",
    "\n",
    "    images=read_all_images()\n",
    "    resultimages=[]\n",
    "    img_labels=[]\n",
    "    def add_iris_to_array(u,j):\n",
    "        X=int(u[0])\n",
    "        Y=int(u[1])\n",
    "        R=int(u[2])\n",
    "\n",
    "        result = images[j][X-R:X+R,Y-R:Y+R]\n",
    "        result = cv2.resize(result,(128,128))\n",
    "        resultimages.append(result)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        file = open('D:\\dersler\\cng483\\Proje3\\CNG483Project 3\\Database/Parameters.txt', \"r\")\n",
    "        lines = file.readlines()[2:]\n",
    "\n",
    "\n",
    "        if(i%8==0):\n",
    "\n",
    "            for z in range(8):\n",
    "\n",
    "                if(z<4):\n",
    "\n",
    "                    if(z==0 or z==1):\n",
    "                        u=lines[i+z].rstrip('\\n').split(',')[1:]\n",
    "                        name = lines[i+z].rstrip('\\n').split(',')[0]\n",
    "                        add_iris_to_array(u,i+z)\n",
    "                    else: \n",
    "                        u=lines[i+z+2].rstrip('\\n').split(',')[1:]\n",
    "                        name = lines[i+z+2].rstrip('\\n').split(',')[0]                        \n",
    "                        add_iris_to_array(u,i+z)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if((z-2)==2 or (z-2)==3):\n",
    "                        u=lines[i+(z-2)].rstrip('\\n').split(',')[1:]\n",
    "                        name = lines[i+(z-2)].rstrip('\\n').split(',')[0]\n",
    "                        add_iris_to_array(u,i+z)\n",
    "                    else  : \n",
    "                        u=lines[i+z].rstrip('\\n').split(',')[1:]\n",
    "                        name = lines[i+z].rstrip('\\n').split(',')[0]\n",
    "                        add_iris_to_array(u,i+z)\n",
    "                img_labels.append(name)\n",
    "    img_labels=np.array(img_labels)\n",
    "    resultimages = np.array(resultimages)\n",
    "\n",
    "    return img_labels,resultimages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e829ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_labels(img_names):\n",
    "    count=1\n",
    "    labels=[]\n",
    "    for i in range(0,len(img_names),8):\n",
    "        label=img_names[i:i+8]\n",
    "        \n",
    "        for j in range(8):\n",
    "            if(j==0 or j==1 or j==4 or j==5):\n",
    "                labels.append(count)\n",
    "            else:\n",
    "                labels.append(count+1)\n",
    "        count+=2\n",
    "    labels=np.array(labels)\n",
    "    return labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "114dd4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bb01d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X,y):\n",
    "    X=X.reshape(-1, 128, 128, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50,stratify=y, shuffle=True, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.50,stratify=y_train, shuffle=True, random_state=1)\n",
    "    # building a linear stack of layers with the sequential model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128,128,1)))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(401, activation='softmax'))\n",
    "    print(model.summary())\n",
    "\t# compile model\n",
    "    opt = RMSprop(learning_rate=0.01, rho=0.9, momentum=0.0)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    batches = 256\n",
    "    epochs=150\n",
    "    # fit model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batches, verbose=1)\n",
    "    plotHistory(model.history)\n",
    "\n",
    "    _, validation_accuracy = model.evaluate(X_val, y_val, batch_size=batches)\n",
    "    _, test_accuracy = model.evaluate(X_test, y_test, batch_size=batches)\n",
    "\n",
    "    print('Validation Accuracy: %f, Test Accuracy: %.3f'  % (validation_accuracy*100, test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc7c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8388736   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 401)               51729     \n",
      "=================================================================\n",
      "Total params: 8,459,281\n",
      "Trainable params: 8,459,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 73039.8203 - acc: 0.0025 - val_loss: 199.6930 - val_acc: 0.0025\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 6180.5327 - acc: 0.0025 - val_loss: 6.0950 - val_acc: 0.0025\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 227.7766 - acc: 0.0025 - val_loss: 5.9992 - val_acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 81.5603 - acc: 0.0025 - val_loss: 5.9899 - val_acc: 0.0025\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 46.4987 - acc: 0.0075 - val_loss: 5.9896 - val_acc: 0.0025\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 32.6267 - acc: 0.0025 - val_loss: 5.9923 - val_acc: 0.0025\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 24.3762 - acc: 0.0000e+00 - val_loss: 5.9934 - val_acc: 0.0025\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 19.3395 - acc: 0.0050 - val_loss: 5.9947 - val_acc: 0.0025\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 16.2482 - acc: 0.0075 - val_loss: 5.9958 - val_acc: 0.0025\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 12.9952 - acc: 0.0025 - val_loss: 5.9970 - val_acc: 0.0025\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 10.4213 - acc: 0.0000e+00 - val_loss: 5.9969 - val_acc: 0.0025\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 8.9722 - acc: 0.0050 - val_loss: 5.9971 - val_acc: 0.0025\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 8.1572 - acc: 0.0025 - val_loss: 5.9974 - val_acc: 0.0025\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.4211 - acc: 0.0125 - val_loss: 5.9977 - val_acc: 0.0025\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 7.1361 - acc: 0.0050 - val_loss: 5.9981 - val_acc: 0.0025\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.7884 - acc: 0.0175 - val_loss: 5.9985 - val_acc: 0.0025\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.6692 - acc: 0.0175 - val_loss: 5.9988 - val_acc: 0.0025\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.6303 - acc: 0.0125 - val_loss: 5.9992 - val_acc: 0.0025\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.6790 - acc: 0.0150 - val_loss: 5.9998 - val_acc: 0.0025\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.7594 - acc: 0.0175 - val_loss: 6.0006 - val_acc: 0.0025\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.4181 - acc: 0.0050 - val_loss: 6.0006 - val_acc: 0.0025\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.3629 - acc: 0.0175 - val_loss: 6.0009 - val_acc: 0.0025\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.1303 - acc: 0.0225 - val_loss: 6.0017 - val_acc: 0.0025\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.0282 - acc: 0.0325 - val_loss: 6.0015 - val_acc: 0.0025\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.2828 - acc: 0.0350 - val_loss: 5.9974 - val_acc: 0.0025\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.3839 - acc: 0.0225 - val_loss: 5.9971 - val_acc: 0.0025\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.0599 - acc: 0.0275 - val_loss: 5.9955 - val_acc: 0.0025\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 6.1229 - acc: 0.0300 - val_loss: 5.9926 - val_acc: 0.0050\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.9192 - acc: 0.0425 - val_loss: 5.9833 - val_acc: 0.0075\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.8617 - acc: 0.0500 - val_loss: 5.9713 - val_acc: 0.0025\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.7584 - acc: 0.0475 - val_loss: 5.9603 - val_acc: 0.0100\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.9926 - acc: 0.0525 - val_loss: 5.9727 - val_acc: 0.0050\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.6311 - acc: 0.0450 - val_loss: 5.9298 - val_acc: 0.0075\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.3632 - acc: 0.0500 - val_loss: 5.9085 - val_acc: 0.0050\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.6418 - acc: 0.0900 - val_loss: 5.9204 - val_acc: 0.0075\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.0232 - acc: 0.1125 - val_loss: 5.9151 - val_acc: 0.0125\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.4431 - acc: 0.0725 - val_loss: 5.9294 - val_acc: 0.0175\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.2511 - acc: 0.1050 - val_loss: 5.9482 - val_acc: 0.0100\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.1374 - acc: 0.1225 - val_loss: 5.9412 - val_acc: 0.0125\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 5.0687 - acc: 0.1275 - val_loss: 6.1066 - val_acc: 0.0325\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 4.5330 - acc: 0.1550 - val_loss: 6.1872 - val_acc: 0.0225\n",
      "Epoch 42/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 4.6344 - acc: 0.1500 - val_loss: 6.2595 - val_acc: 0.0350\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 4.4660 - acc: 0.1675 - val_loss: 6.0395 - val_acc: 0.0225\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 4.5484 - acc: 0.1575 - val_loss: 6.4306 - val_acc: 0.0350\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 4.2748 - acc: 0.1950 - val_loss: 6.2789 - val_acc: 0.0300\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 4.2746 - acc: 0.1775 - val_loss: 7.2867 - val_acc: 0.0450\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 4.0934 - acc: 0.2550 - val_loss: 6.8639 - val_acc: 0.0325\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.9513 - acc: 0.2325 - val_loss: 7.5439 - val_acc: 0.0550\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.7284 - acc: 0.2925 - val_loss: 7.0619 - val_acc: 0.0375\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.5398 - acc: 0.2825 - val_loss: 7.3967 - val_acc: 0.0425\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.5906 - acc: 0.3225 - val_loss: 7.8035 - val_acc: 0.0400\n",
      "Epoch 52/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.4488 - acc: 0.3325 - val_loss: 9.7515 - val_acc: 0.0500\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2247 - acc: 0.3825 - val_loss: 7.4964 - val_acc: 0.0500\n",
      "Epoch 54/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.1459 - acc: 0.3875 - val_loss: 8.6145 - val_acc: 0.0650\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.7904 - acc: 0.4350 - val_loss: 8.7083 - val_acc: 0.0575\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.0017 - acc: 0.4150 - val_loss: 9.4146 - val_acc: 0.0650\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.1409 - acc: 0.4050 - val_loss: 11.3378 - val_acc: 0.0500\n",
      "Epoch 58/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.8915 - acc: 0.3350 - val_loss: 9.4284 - val_acc: 0.0750\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.6526 - acc: 0.4550 - val_loss: 10.2323 - val_acc: 0.0700\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.4461 - acc: 0.4825 - val_loss: 10.5783 - val_acc: 0.0625\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 2.5319 - acc: 0.4650 - val_loss: 10.7667 - val_acc: 0.0550\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 2.2093 - acc: 0.5575 - val_loss: 12.2136 - val_acc: 0.0650\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 2.1095 - acc: 0.5500 - val_loss: 11.8664 - val_acc: 0.0850\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 2.1279 - acc: 0.5800 - val_loss: 12.5623 - val_acc: 0.0725\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.9665 - acc: 0.6000 - val_loss: 12.7721 - val_acc: 0.0725\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6643 - acc: 0.6125 - val_loss: 14.2711 - val_acc: 0.0725\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.9466 - acc: 0.5900 - val_loss: 15.3318 - val_acc: 0.0750\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6449 - acc: 0.6850 - val_loss: 13.7007 - val_acc: 0.0775\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.6674 - acc: 0.6675 - val_loss: 14.4524 - val_acc: 0.0800\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.4333 - acc: 0.6850 - val_loss: 14.7294 - val_acc: 0.0800\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5287 - acc: 0.6825 - val_loss: 16.6005 - val_acc: 0.0925\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5492 - acc: 0.6875 - val_loss: 17.6491 - val_acc: 0.0825\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.8137 - acc: 0.6850 - val_loss: 16.6177 - val_acc: 0.0875\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.2837 - acc: 0.7425 - val_loss: 16.3683 - val_acc: 0.0700\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3277 - acc: 0.7575 - val_loss: 17.2565 - val_acc: 0.0600\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3959 - acc: 0.7275 - val_loss: 17.9621 - val_acc: 0.0675\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.8138 - acc: 0.6900 - val_loss: 19.3148 - val_acc: 0.0725\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9885 - acc: 0.7050 - val_loss: 22.6740 - val_acc: 0.0875\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.9087 - acc: 0.7100 - val_loss: 20.5716 - val_acc: 0.0900\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.1767 - acc: 0.6625 - val_loss: 19.7005 - val_acc: 0.0900\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.1940 - acc: 0.7650 - val_loss: 18.4913 - val_acc: 0.0825\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5608 - acc: 0.7475 - val_loss: 18.9209 - val_acc: 0.0775\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0952 - acc: 0.7775 - val_loss: 22.0969 - val_acc: 0.0700\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.4451 - acc: 0.7975 - val_loss: 21.2972 - val_acc: 0.0975\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8995 - acc: 0.8050 - val_loss: 21.9654 - val_acc: 0.0950\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.9995 - acc: 0.8075 - val_loss: 25.0715 - val_acc: 0.0950\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.1122 - acc: 0.8100 - val_loss: 21.4605 - val_acc: 0.0875\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1205 - acc: 0.8150 - val_loss: 25.7665 - val_acc: 0.0875\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.6981 - acc: 0.8050 - val_loss: 26.1656 - val_acc: 0.0800\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.3095 - acc: 0.7925 - val_loss: 22.8405 - val_acc: 0.0775\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.1161 - acc: 0.7900 - val_loss: 24.0356 - val_acc: 0.0925\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5637 - acc: 0.7875 - val_loss: 24.2654 - val_acc: 0.0850\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.1132 - acc: 0.7800 - val_loss: 24.1490 - val_acc: 0.1075\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8493 - acc: 0.8500 - val_loss: 27.8155 - val_acc: 0.0975\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0949 - acc: 0.8275 - val_loss: 27.5277 - val_acc: 0.0950\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0514 - acc: 0.8300 - val_loss: 27.3467 - val_acc: 0.1000\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0427 - acc: 0.8325 - val_loss: 29.2205 - val_acc: 0.0925\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0989 - acc: 0.8375 - val_loss: 27.0758 - val_acc: 0.0800\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.9493 - acc: 0.8275 - val_loss: 29.1336 - val_acc: 0.0875\n",
      "Epoch 100/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7937 - acc: 0.8550 - val_loss: 29.6946 - val_acc: 0.0975\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0388 - acc: 0.8350 - val_loss: 29.8428 - val_acc: 0.1000\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0665 - acc: 0.8700 - val_loss: 29.4473 - val_acc: 0.1050\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0009 - acc: 0.8650 - val_loss: 33.5162 - val_acc: 0.0925\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.9882 - acc: 0.8550 - val_loss: 32.5309 - val_acc: 0.0900\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7416 - acc: 0.8850 - val_loss: 32.4286 - val_acc: 0.0875\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8207 - acc: 0.8650 - val_loss: 36.0714 - val_acc: 0.1000\n",
      "Epoch 107/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9069 - acc: 0.8775 - val_loss: 33.7599 - val_acc: 0.0875\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9105 - acc: 0.8875 - val_loss: 35.9411 - val_acc: 0.0950\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6883 - acc: 0.8950 - val_loss: 33.5975 - val_acc: 0.0975\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3257 - acc: 0.8200 - val_loss: 38.6167 - val_acc: 0.0875\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8448 - acc: 0.8925 - val_loss: 33.7395 - val_acc: 0.1000\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7100 - acc: 0.8700 - val_loss: 33.8093 - val_acc: 0.1050\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0489 - acc: 0.8625 - val_loss: 35.6607 - val_acc: 0.0975\n",
      "Epoch 114/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8607 - acc: 0.8725 - val_loss: 36.8270 - val_acc: 0.1025\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8553 - acc: 0.8750 - val_loss: 36.8938 - val_acc: 0.0975\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4576 - acc: 0.9225 - val_loss: 36.6777 - val_acc: 0.1000\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4672 - acc: 0.9200 - val_loss: 34.3622 - val_acc: 0.0975\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5610 - acc: 0.9250 - val_loss: 37.2027 - val_acc: 0.1025\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7034 - acc: 0.9150 - val_loss: 39.1942 - val_acc: 0.1050\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5618 - acc: 0.9150 - val_loss: 41.2487 - val_acc: 0.1000\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7246 - acc: 0.9025 - val_loss: 41.5542 - val_acc: 0.1000\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4503 - acc: 0.9225 - val_loss: 39.7622 - val_acc: 0.0825\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4691 - acc: 0.9350 - val_loss: 42.0968 - val_acc: 0.0975\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6042 - acc: 0.9225 - val_loss: 42.6202 - val_acc: 0.1050\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6819 - acc: 0.9050 - val_loss: 40.3225 - val_acc: 0.0875\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.5905 - acc: 0.8475 - val_loss: 56.1384 - val_acc: 0.0800\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7992 - acc: 0.8975 - val_loss: 53.9704 - val_acc: 0.1075\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8145 - acc: 0.9200 - val_loss: 52.5950 - val_acc: 0.1150\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0481 - acc: 0.9025 - val_loss: 52.7979 - val_acc: 0.0950\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0668 - acc: 0.9075 - val_loss: 48.8797 - val_acc: 0.0900\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8206 - acc: 0.9050 - val_loss: 55.9916 - val_acc: 0.0975\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6332 - acc: 0.9025 - val_loss: 54.4794 - val_acc: 0.1000\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1117 - acc: 0.8800 - val_loss: 55.0643 - val_acc: 0.0925\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8861 - acc: 0.9075 - val_loss: 55.1028 - val_acc: 0.0850\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8115 - acc: 0.9150 - val_loss: 55.4971 - val_acc: 0.0925\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5417 - acc: 0.9400 - val_loss: 55.5314 - val_acc: 0.0900\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.9771 - acc: 0.9000 - val_loss: 57.3965 - val_acc: 0.1000\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6189 - acc: 0.9350 - val_loss: 61.0260 - val_acc: 0.1150\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5758 - acc: 0.9300 - val_loss: 59.5901 - val_acc: 0.1000\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6666 - acc: 0.9275 - val_loss: 58.9742 - val_acc: 0.1100\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6078 - acc: 0.9400 - val_loss: 60.8683 - val_acc: 0.1175\n",
      "Epoch 142/150\n"
     ]
    }
   ],
   "source": [
    "img_names,img_crops= get_iris_crop() # Read all data and get the iris part, image_names-> names of the images, img_crops-> preprocessed images\n",
    "img_labels=determine_labels(img_names) # Label the images based on their names\n",
    "\n",
    "\n",
    "\n",
    "CNN(img_crops,img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95648190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
